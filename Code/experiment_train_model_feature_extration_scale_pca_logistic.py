# -*- coding: utf-8 -*-
"""Experiment_Train_Model_Feature_Extration_SCALE_PCA_Logistic

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16JGKuLSlwGbfrJSqxcf9ptIHXOz0WDLK

1) Επιλέξτε ένα πρόβλημα κατηγοριοποιήσης συναισθημάτων (π.χ. "calm"-"angry"), επιλέξτε τα κατάλληλα χαρακτηριστικά ήχου (ανάμεσα σε MFCCs, spectral centroid & bandwidth) και επιλέξτε και εκπαιδεύστε ένα μοντέλο μηχανικής μάθησης (όσο απλό κι αν είναι), παρουσιάζοντας αποτελέσματα της αξιολόγησής του, όχι σε πραγματικό χρόνο (δηλαδή με τη διαδικασία χωρισμού σε δεδομένα εκπαίδευσης-ελέγχου, όπως κάναμε στο μάθημα 8). Αποθηκεύστε το μοντέλο αυτό για φόρτωμα και χρήση στο πρόγραμμα πραγματικού χρόνου που θα φτιάξετε αργότερα.

#Speech Emotion Binary Classification task
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.decomposition import PCA
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn import metrics
from sklearn.svm import SVC
import pickle

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_pickle('/content/drive/MyDrive/Τελική εργασία - Ήχος - 2022-2023/prepared_dataframe.pickle')
print(df)
df.shape

act_c = df[ (df['emotion'] == 'calm')]
act_a = df[ (df['emotion'] == 'angry')]
folder_for_figs = 'act_c_a'

"""Isolate features and labels"""

a_c = np.stack( act_c['mfcc_profile'].to_numpy() )
b_c = act_c[['mean_centroid', 'std_centroid', 'mean_bandwidth', 'std_bandwidth']].to_numpy()

a_a = np.stack( act_a['mfcc_profile'].to_numpy() )
b_a = act_a[['mean_centroid', 'std_centroid', 'mean_bandwidth', 'std_bandwidth']].to_numpy()

act_c_features = np.c_[ a_c , b_c ]
act_a_features = np.c_[ a_a , b_a ]

all_features = np.vstack((act_c_features, act_a_features))

act_c_labels = 0*np.ones( ( act_c_features.shape[0] , 1 ) )
act_a_labels = 1*np.ones( ( act_a_features.shape[0] , 1 ) )
all_labels = np.r_[act_c_labels , act_a_labels]

# %% train - test split

from sklearn.model_selection import train_test_split
train_set , test_set = train_test_split( np.c_[ all_features , all_labels] , test_size=0.2 , random_state=42 )

X_train = train_set[:, :-1]
y_train = train_set[:, -1]
X_test = test_set[:, :-1]
y_test = test_set[:, -1]

#Feature Scaling of the features in the Training and Test Set
scalerx = StandardScaler()
X_train_scaled = scalerx.fit_transform(X_train)
X_train_scaled = pd.DataFrame(X_train_scaled)
X_test_scaled = scalerx.transform(X_test)
X_test_scaled = pd.DataFrame(X_test_scaled)

pca =PCA(n_components =2)
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)
print(pca.explained_variance_ratio_.cumsum())

# Scatter Plot of Training and Test Set with labels indicated by colors
plt.figure(figsize = (20, 6))
plt.subplot(1, 2, 1)
plt.scatter(X_train_pca[:,0], X_train_pca[:,1], c = y_train)
plt.xlabel('Training 1st Principal Component')
plt.ylabel('Training 2nd Principal Component')
plt.title('Training Set Scatter Plot with labels indicated by colors i.e., (0) -> Violet and (1) -> Yellow')
plt.subplot(1, 2, 2)
plt.scatter(X_test_pca[:,0], X_test_pca[:,1], c = y_test)
plt.xlabel('Test 1st Principal Component')
plt.ylabel('Test 2nd Principal Component')
plt.title('Test Set Scatter Plot with labels indicated by colors i.e., (0) -> Violet and (1) -> Yellow')
plt.show()

"""Based on the above PCA, 2 variables are enough to explain 91% of the variance of the dataset. So we can limit our dimension to 2 and visualize our data."""

#Performing 5-Fold Grid-Search Cross Validation on Logistic Regression Classifier on the Training Set

# 5-Fold Grid-Search Cross Validation on Logistic Regression Classifier for tuning the hyper-parameter, C with Accuracy scoring
params = {'C':[0.01, 0.1, 1, 10, 100]}

clf = LogisticRegression()

folds = 5
model_cv = GridSearchCV(estimator = clf,
                        param_grid = params,
                        scoring= 'accuracy',
                        cv = folds,
                        return_train_score=True,
                        verbose = 3)

model_cv.fit(X_train_pca, y_train)

# getting the best hyper-parameter
print(model_cv.best_params_)

#Re-training the Logistic Regression Classifier with the best hyper-parameter, C = 1 (obtained above)
model = LogisticRegression(C = 1).fit(X_train_pca, y_train)

"""Obtaining the Training Set and Test Set Predictions given by the model"""

# getting the Training Set Predictions
y_train_pred = model.predict(X_train_pca)

# getting the Test Set Predictions
y_test_pred = model.predict(X_test_pca)

# Getting the Training and Test Accuracy
print('Training Accuracy of the Model: ', metrics.accuracy_score(y_train, y_train_pred))
print('Test Accuracy of the Model: ', metrics.accuracy_score(y_test, y_test_pred))
print()

# Getting the Training and Test Precision
print('Training Precision of the Model: ', metrics.precision_score(y_train, y_train_pred))
print('Test Precision of the Model: ', metrics.precision_score(y_test, y_test_pred))
print()

# Getting the Training and Test Recall
print('Training Recall of the Model: ', metrics.recall_score(y_train, y_train_pred))
print('Test Recall of the Model: ', metrics.recall_score(y_test, y_test_pred))
print()

# Getting the Training and Test F1-Score
print('Training F1-Score of the Model: ', metrics.f1_score(y_train, y_train_pred))
print('Test F1-Score of the Model: ', metrics.f1_score(y_test, y_test_pred))
print()

"""Plotting the Decision Boundary given by the Trained Logistic Regression both on the Training and Test sets"""

# plotting the decision boundary in the scatter plot of Training and Test Set with labels indicated by colors
x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1
y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1

xx_train, yy_train = np.meshgrid(np.arange(x_min, x_max, 0.1),
                                 np.arange(y_min, y_max, 0.1))

Z_train = model.predict(np.c_[xx_train.ravel(), yy_train.ravel()])
Z_train = Z_train.reshape(xx_train.shape)


x_min, x_max = X_test_pca[:, 0].min() - 1, X_test_pca[:, 0].max() + 1
y_min, y_max = X_test_pca[:, 1].min() - 1, X_test_pca[:, 1].max() + 1

xx_test, yy_test = np.meshgrid(np.arange(x_min, x_max, 0.1),
                               np.arange(y_min, y_max, 0.1))

Z_test = model.predict(np.c_[xx_test.ravel(), yy_test.ravel()])
Z_test = Z_test.reshape(xx_test.shape)

plt.figure(figsize = (20, 6))
plt.subplot(1, 2, 1)
plt.contourf(xx_train, yy_train, Z_train)
plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c = y_train, s = 30, edgecolor = 'k')
plt.xlabel('Training 1st Principal Component')
plt.ylabel('Training 2nd Principal Component')
plt.title('Scatter Plot with Decision Boundary for the Training Set')
plt.subplot(1, 2, 2)
plt.contourf(xx_test, yy_test, Z_test)
plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c = y_test, s = 30, edgecolor = 'k')
plt.xlabel('Test 1st Principal Component')
plt.ylabel('Test 2nd Principal Component')
plt.title('Scatter Plot with Decision Boundary for the Test Set')
plt.show()

"""#Cross validation - custom accuracy metric"""

from sklearn.metrics import make_scorer
from sklearn.model_selection import cross_val_score

def binary_accuracy( y_true , y_pred ):
        bin_pred = np.array( y_pred >= 0.5 ).astype(int)
        return np.sum( y_true == bin_pred ) / y_true.size

my_scorer = make_scorer(binary_accuracy, greater_is_better=True)
scores_logistic = cross_val_score( model, all_features, all_labels.ravel(), scoring=my_scorer, cv=10 )

def present_scores( s , algorithm='method' ):
    print(30*'-')
    print( algorithm + ' accuracy in 10-fold cross validation:' )
    print('mean: ' + str( np.mean(s) ))
    print('std: ' + str( np.std(s) ))
    print('median: ' + str( np.median(s) ))

present_scores( scores_logistic, algorithm= 'Logistic Regression' )

"""#Save model"""

save = open("./trained.pickle","wb")
pickle.dump(model,save)
save.close()